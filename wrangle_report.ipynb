{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> <center> Data Wrangling : WeRateDogs (@DogRates) </center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main purpose of this project was to use real world data to wrangle (gather, assess, clean) and then apply analysis with visualizations. The data used was from the Twitter account ‘WeRateDogs’ (@dog_rates) which “rates people's dogs with a humorous comments about the dog. These ratings almost always have a denominator of 10. The numerators, though? Almost always greater than 10. 11/10, 12/10, 13/10, etc.”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps Involved in data Wrangling:\n",
    "    1. Gathering the data\n",
    "    2. Assesing the data\n",
    "    3. Cleaning the data\n",
    "    4. Storing the final cleaned dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I started off with gathering the data from various sources, then used jupyter notebook to access that data and then made some observations visually and programatically on the areas that needs cleaning and tidiness in order to make data more usable. After I made my assessments, next step was to use python to clean the data for each of the issues identified in the assesing phase. Once the data was cleaned, I joined different datasets together to develop a master dataset that was further used to get some insights from the data using data visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will briefly discuss about each of the phases in this document below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Gathering data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I had to gather data from three different sources as below:\n",
    "\n",
    "   1. Read the csv file which contains the WeRateDogs Twitter archive data (twitter_archive_enhanced.csv)\n",
    "   2. Use the Requests library to download the tweet image prediction into a file called image_predictions.tsv.\n",
    "   3. Use the Tweepy library to query additional data via the Twitter API (tweet_json.txt), since tweepy is now paid. Udacity provided us with the json file with the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the above were stored in the form of pandas dataframes to perform further assessments and cleaning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Assessing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After doing the visual and programmatic assessments, I was able to identify the below quality and tidiness issues in the dataframes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quality Issues\n",
    "\n",
    "1. tweets_data dataframe     ---   There are retweets and replied tweets also present in the dataset, since we only need original tweets, we need to remove retweets and replied tweets.\n",
    "\n",
    "2. tweets_data dataframe     ---   Incorrect format of timestamp, it is string but should be timestamp\n",
    " \n",
    "3. tweets_data dataframe     ---   Column 'source' is in anchor tag and is unreadable, extract the source out as text.\n",
    "\n",
    "4. img_predictions dataframe ---   Keep records which only have dog names in either p1, p2 or p3 i.e. model confirm that the image is of a dog\n",
    "\n",
    "5. tweets_data dataframe     ---   rating_denominator should always be 10 but there are other values in the  tweets_data_clean dataframe, Identify the tweets which have values other than 10 and fix the denominator\n",
    "\n",
    "6. tweets_data dataframe     ---   Some tweets have more than 1 dog stage ex: pupper, duggo both as dog stage. Fix it to right dog stage.\n",
    "\n",
    "7. tweets_data dataframe     ---   name column have unrelevant values None, a, the, an\n",
    "\n",
    "8. img_predictions dataframe ---   p1,p2,p3 columns in img_predictions dataframe has inconsistent capitalization and also contain underscores in dog names\n",
    "\n",
    "#### Tidiness Issues\n",
    "\n",
    "1. tweets_data dataframe --- Remove extra columns which are no longer needed : in_reply_to_status_id, in_reply_to_user_id, retweeted_status_id , retweeted_status_user_id\n",
    "\n",
    "2. tweets_data dataframe --- doggo, floofer, pupper, puppo should not be 4 columns but value of a single column, something like 'dog_stage'\n",
    "\n",
    "3. No need for 3 separate datasets. All datasets can be merged into a single dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Cleaning data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After I identified the quality and tidiness issues in the data, it was time to fix them using pandas and build clean datasets.\n",
    "I will briefly describe in one or two lines about the approach I opted to fix each of the issues identified in the assessing phase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality Issues \n",
    "\n",
    "\n",
    "#### Issue 1 : \n",
    "Definition : tweets_data dataframe     ---   There are retweets and replied tweets also present in the dataset, since we only need original tweets, we needed to remove retweets and replied tweets.\n",
    "\n",
    "Solution : Dropped the records where there is a non-null value in columns - retweeted_status_id , in_reply_to_status_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Issue 2 : \n",
    "Definition : tweets_data dataframe     ---   Incorrect format of timestamp, it is string but should be timestamp\n",
    "\n",
    "Solution : Removeed trailing \" +0000\" i.e. last 6 characters and converted to datetime format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Issue 3 : \n",
    "Definition : tweets_data dataframe   ---   Column 'source' is in anchor tag and is unreadable, extract the source out as text.\n",
    "\n",
    "Solution : Used split function and pull out the actual text from anchor tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Issue 4 : \n",
    "Definition : img_predictions dataframe ---   Keep records which only have dog names in either p1, p2 or p3 i.e. model confirm that the image is of a dog.\n",
    "\n",
    "Solution : Created a list of such tweets which have p1_dog,p2_dog and p3_dog as FALSE and removed these tweets from all three dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Issue 5 : \n",
    "Definition : rating_denominator should always be 10 but there are other values in the tweets_data_clean dataframe, Identify the tweets which have values other than 10 and fix the denominator\n",
    "\n",
    "Solution : Created a list with contains the wrong denomiantors (other than 10) and then fetched the tweets with those denominators. Since there were handful of tweets, Fixed the ratings individually upon reading the tweets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Issue 6 : \n",
    "Definition : tweets_data dataframe --- Some tweets have more than 1 dog stage ex: pupper, duggo both as dog stage. Fix it to right dog stage.\n",
    "\n",
    "Solution : Created a new column called 'combined_stages' but concatenating all four fields and then replace the string 'None' with blank value, so that we can identify the tweets with singlular dog type and multiple dog types easily.\n",
    "Replacing '' with 'None' back again for the records which had 'NoneNoneNoneNone' Values\n",
    "Upon identifying multiple dog type records, fixed it accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Issue 7 : \n",
    "Definition : tweets_data dataframe  ---  'name' column have irrelevant values None, a, the, an\n",
    "\n",
    "Solution : Replaced values with NaN where there is irrelevant names - None, a, the, an"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Issue 8 :\n",
    "\n",
    "Definition : p1,p2,p3 columns in img_predictions_dataframe has inconsistent capitalization and also contain underscores in dog names\n",
    "\n",
    "Solution : Capitalized the dog names and replaced underscores with a single space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tidiness Issues\n",
    "\n",
    "\n",
    "#### Issue 1 :\n",
    "\n",
    "Definition : tweets_data dataframe --- Remove extra columns which are no longer needed : in_reply_to_status_id, in_reply_to_user_id, retweeted_status_id , retweeted_status_user_id, retweeted_status_timestamp\n",
    "    \n",
    "Solution : Used drop method to drop the required columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Issue 2 :\n",
    "\n",
    "Definition : tweets_data dataframe --- doggo, floofer, pupper, puppo should not be 4 columns but value of a single column, something like 'dog_stage'\n",
    "    \n",
    "Solution : Drop 4 columns and rename combined_stages column to dog_stage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing cleaned dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finaly I joined  the above 3 datasets into a single dataset I saved the master joined dataset as twitter_archive_master.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
